#!/usr/bin/env python3
"""
STREAMING PREDICTIVE PROCESSOR
–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—ã –í–û –í–†–ï–ú–Ø —Ä–µ—á–∏, –Ω–µ –æ–∂–∏–¥–∞—è –ø–∞—É–∑
"""

import asyncio
import time
import re
import logging
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import numpy as np

logger = logging.getLogger(__name__)

class StreamingState(Enum):
    """–°–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    LISTENING = "listening"
    DETECTING = "detecting" 
    PROCESSING = "processing"
    CONFIRMING = "confirming"
    EXECUTING = "executing"

@dataclass
class StreamingCommand:
    """–ü–æ—Ç–æ–∫–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞"""
    pattern_type: str
    confidence: float
    extracted_data: Dict
    partial_text: str
    timestamp: float
    state: StreamingState

class StreamingPredictor:
    """–ü—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ—Ç–æ–∫–∞ —Ä–µ—á–∏"""
    
    def __init__(self, web_clients_ref):
        self.web_clients = web_clients_ref
        self.active_streams = {}  # client_id -> stream data
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —É–ª—å—Ç—Ä–∞-–±—ã—Å—Ç—Ä–æ–≥–æ —Ä–µ–∂–∏–º–∞
        self.min_analysis_length = 6    # –ú–∏–Ω–∏–º—É–º —Å–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.confidence_threshold = 0.75
        self.execution_threshold = 0.85
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        self.setup_streaming_patterns()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'predictions_made': 0,
            'early_executions': 0,
            'false_positives': 0,
            'average_prediction_time': 0.0,
            'accuracy_rate': 0.0
        }
        
        logger.info("üîÆ STREAMING PREDICTOR initialized for ULTRA-FAST mode")
    
    def setup_streaming_patterns(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        
        # –ë—ã—Å—Ç—Ä—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (—Å—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç —Ä–∞–Ω–æ)
        self.quick_patterns = {
            'probing_depth_start': re.compile(
                r'probing\s+depth.*tooth\s+(?:number\s+)?(\w+)', 
                re.IGNORECASE
            ),
            'bleeding_start': re.compile(
                r'bleeding.*tooth\s+(\w+)', 
                re.IGNORECASE
            ),
            'mobility_start': re.compile(
                r'tooth\s+(\w+).*mobility', 
                re.IGNORECASE
            ),
            'missing_start': re.compile(
                r'missing\s+teeth?\s+(\w+)', 
                re.IGNORECASE
            )
        }
        
        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (–ø–æ–ª–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞)
        self.confirmation_patterns = {
            'probing_depth_full': re.compile(
                r'probing\s+depth.*tooth\s+(?:number\s+)?(\w+).*?(buccal|lingual).*?(\d+)\s+(\d+)\s+(\d+)',
                re.IGNORECASE
            ),
            'bleeding_full': re.compile(
                r'bleeding.*tooth\s+(\w+)\s+(buccal|lingual)\s+(distal|mesial|mid)',
                re.IGNORECASE
            ),
            'mobility_full': re.compile(
                r'tooth\s+(\w+).*mobility.*grade\s+(\d+)',
                re.IGNORECASE
            ),
            'missing_full': re.compile(
                r'missing\s+teeth?\s+([\w\s]+)',
                re.IGNORECASE
            )
        }
        
        # –°–ª–æ–≤–∞—Ä—å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Å–ª–æ–≤ –≤ —á–∏—Å–ª–∞ (—Å ASR –æ—à–∏–±–∫–∞–º–∏)
        self.word_to_num = {
            'zero': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,
            'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10,
            'eleven': 11, 'twelve': 12, 'thirteen': 13, 'fourteen': 14,
            'fifteen': 15, 'sixteen': 16, 'seventeen': 17, 'eighteen': 18,
            'nineteen': 19, 'twenty': 20, 'thirty': 30, 'thirty-one': 31, 'thirty-two': 32,
            
            # ASR –æ—à–∏–±–∫–∏
            'too': 2, 'to': 2, 'for': 4, 'ate': 8, 'won': 1, 'tree': 3, 'sex': 6
        }
    
    async def process_streaming_chunk(self, client_id: str, partial_text: str, 
                                    audio_buffer: np.ndarray) -> Optional[Dict]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ —á–∞–Ω–∫–∞ - –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
        """
        start_time = time.time()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Ç–æ–∫–∞ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞
        if client_id not in self.active_streams:
            self.active_streams[client_id] = {
                'partial_texts': [],
                'predictions': [],
                'last_prediction': None,
                'start_time': start_time,
                'word_count': 0
            }
        
        stream = self.active_streams[client_id]
        stream['partial_texts'].append(partial_text)
        stream['word_count'] = len(partial_text.split())
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–ª–æ–≤
        if stream['word_count'] < self.min_analysis_length:
            logger.debug(f"üîÆ Not enough words yet: {stream['word_count']}/{self.min_analysis_length}")
            return None
        
        logger.info(f"üîÆ STREAMING ANALYSIS: '{partial_text}' ({stream['word_count']} words)")
        
        # –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        prediction = await self.analyze_patterns(partial_text, client_id)
        
        if prediction:
            stream['predictions'].append(prediction)
            self.stats['predictions_made'] += 1
            
            prediction_time = (time.time() - start_time) * 1000
            logger.info(f"‚ö° PREDICTION made in {prediction_time:.1f}ms: {prediction.pattern_type}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–∂–Ω–æ –ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –¥–æ—Å—Ä–æ—á–Ω–æ
            if prediction.confidence >= self.execution_threshold:
                logger.info(f"üöÄ EARLY EXECUTION triggered! Confidence: {prediction.confidence:.2f}")
                
                # –ú–≥–Ω–æ–≤–µ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
                result = await self.execute_early_command(client_id, prediction)
                
                if result:
                    self.stats['early_executions'] += 1
                    
                    # –£–≤–µ–¥–æ–º–ª—è–µ–º –∫–ª–∏–µ–Ω—Ç–∞ –æ –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏
                    await self.broadcast_early_execution(client_id, result, prediction_time)
                    
                    return result
            
            elif prediction.confidence >= self.confidence_threshold:
                # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –≥–æ—Ç–æ–≤–∏–º –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é
                logger.info(f"üéØ HIGH CONFIDENCE: {prediction.confidence:.2f} - preparing for execution")
                stream['last_prediction'] = prediction
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
                await self.broadcast_prediction_feedback(client_id, prediction)
        
        return None
    
    async def analyze_patterns(self, text: str, client_id: str) -> Optional[StreamingCommand]:
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –ø–æ—Ç–æ–∫–æ–≤–æ–º —Ç–µ–∫—Å—Ç–µ"""
        
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –±—ã—Å—Ç—Ä—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞–Ω–Ω–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
        for pattern_name, pattern_regex in self.quick_patterns.items():
            match = pattern_regex.search(text)
            if match:
                confidence = self.calculate_pattern_confidence(text, pattern_name, match)
                
                if confidence >= self.confidence_threshold:
                    logger.info(f"‚úÖ QUICK PATTERN matched: {pattern_name} (conf: {confidence:.2f})")
                    
                    # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ
                    extracted_data = await self.extract_command_data(text, pattern_name, match)
                    
                    if extracted_data:
                        return StreamingCommand(
                            pattern_type=pattern_name,
                            confidence=confidence,
                            extracted_data=extracted_data,
                            partial_text=text,
                            timestamp=time.time(),
                            state=StreamingState.PROCESSING
                        )
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
        for pattern_name, pattern_regex in self.confirmation_patterns.items():
            match = pattern_regex.search(text)
            if match:
                confidence = self.calculate_pattern_confidence(text, pattern_name, match)
                
                logger.info(f"üéØ FULL PATTERN matched: {pattern_name} (conf: {confidence:.2f})")
                
                extracted_data = await self.extract_command_data(text, pattern_name, match)
                
                if extracted_data:
                    return StreamingCommand(
                        pattern_type=pattern_name,
                        confidence=min(confidence + 0.1, 1.0),  # –ë–æ–Ω—É—Å –∑–∞ –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                        extracted_data=extracted_data,
                        partial_text=text,
                        timestamp=time.time(),
                        state=StreamingState.CONFIRMING
                    )
        
        return None
    
    def calculate_pattern_confidence(self, text: str, pattern_name: str, match) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–µ"""
        base_confidence = 0.7
        
        # –ë–æ–Ω—É—Å—ã –∑–∞ –ø–æ–ª–Ω–æ—Ç—É
        word_count = len(text.split())
        if word_count >= 8:
            base_confidence += 0.15
        elif word_count >= 6:
            base_confidence += 0.1
        
        # –ë–æ–Ω—É—Å –∑–∞ —á–∏—Å–ª–∞
        numbers_found = len(re.findall(r'\d+', text))
        if numbers_found >= 3:
            base_confidence += 0.1
        elif numbers_found >= 1:
            base_confidence += 0.05
        
        # –ë–æ–Ω—É—Å –∑–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        dental_keywords = ['tooth', 'buccal', 'lingual', 'distal', 'mesial', 'grade', 'class']
        keywords_found = sum(1 for keyword in dental_keywords if keyword in text.lower())
        base_confidence += keywords_found * 0.02
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–ª–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        if 'full' in pattern_name:
            base_confidence += 0.1
        
        return min(base_confidence, 1.0)
    
    async def extract_command_data(self, text: str, pattern_name: str, match) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–∞–Ω–¥—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        
        def convert_word_to_number(word: str) -> int:
            """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å–ª–æ–≤ –≤ —á–∏—Å–ª–∞"""
            if not word:
                return 0
            
            clean_word = word.lower().strip('.,!?;:')
            
            if clean_word.isdigit():
                return int(clean_word)
            
            return self.word_to_num.get(clean_word, 0)
        
        try:
            if 'probing_depth' in pattern_name:
                tooth = convert_word_to_number(match.group(1))
                
                if 'full' in pattern_name and len(match.groups()) >= 5:
                    surface = match.group(2).lower()
                    depth1 = int(match.group(3))
                    depth2 = int(match.group(4)) 
                    depth3 = int(match.group(5))
                    
                    if 1 <= tooth <= 32 and all(1 <= d <= 12 for d in [depth1, depth2, depth3]):
                        return {
                            'type': 'probing_depth',
                            'tooth_number': tooth,
                            'surface': surface,
                            'values': [depth1, depth2, depth3],
                            'complete': True
                        }
                
                elif 1 <= tooth <= 32:
                    # –ß–∞—Å—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ - –ø–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –±–æ–ª—å—à–µ
                    numbers = [int(x) for x in re.findall(r'\b(\d+)\b', text) if 1 <= int(x) <= 12 and int(x) != tooth]
                    surface = 'buccal' if 'buccal' in text.lower() else ('lingual' if 'lingual' in text.lower() else 'buccal')
                    
                    if len(numbers) >= 3:
                        return {
                            'type': 'probing_depth',
                            'tooth_number': tooth,
                            'surface': surface,
                            'values': numbers[:3],
                            'complete': True
                        }
                    else:
                        return {
                            'type': 'probing_depth',
                            'tooth_number': tooth,
                            'surface': surface,
                            'complete': False
                        }
            
            elif 'bleeding' in pattern_name:
                tooth = convert_word_to_number(match.group(1))
                
                if 1 <= tooth <= 32:
                    surface = 'buccal'
                    position = 'distal'
                    
                    if 'full' in pattern_name and len(match.groups()) >= 3:
                        surface = match.group(2).lower()
                        position = match.group(3).lower()
                    else:
                        # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –∏–∑ —Ç–µ–∫—Å—Ç–∞
                        if 'lingual' in text.lower():
                            surface = 'lingual'
                        if 'mesial' in text.lower():
                            position = 'mesial'
                        elif 'mid' in text.lower():
                            position = 'mid'
                    
                    return {
                        'type': 'bleeding',
                        'tooth_number': tooth,
                        'surface': surface,
                        'position': position,
                        'values': [True],
                        'complete': 'full' in pattern_name
                    }
            
            elif 'mobility' in pattern_name:
                tooth = convert_word_to_number(match.group(1))
                
                if 1 <= tooth <= 32:
                    grade = 2  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                    
                    if 'full' in pattern_name and len(match.groups()) >= 2:
                        grade = int(match.group(2))
                    else:
                        # –ò—â–µ–º grade –≤ —Ç–µ–∫—Å—Ç–µ
                        grade_match = re.search(r'grade\s+(\d+)', text.lower())
                        if grade_match:
                            grade = int(grade_match.group(1))
                    
                    if 0 <= grade <= 3:
                        return {
                            'type': 'mobility',
                            'tooth_number': tooth,
                            'values': [grade],
                            'complete': 'full' in pattern_name
                        }
            
            elif 'missing' in pattern_name:
                if 'full' in pattern_name:
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ –∑—É–±–æ–≤
                    teeth_text = match.group(1)
                    teeth_numbers = []
                    
                    for word in teeth_text.split():
                        tooth_num = convert_word_to_number(word)
                        if 1 <= tooth_num <= 32:
                            teeth_numbers.append(tooth_num)
                    
                    if teeth_numbers:
                        return {
                            'type': 'missing_teeth',
                            'values': teeth_numbers,
                            'complete': True
                        }
                else:
                    # –û–¥–∏–Ω –∑—É–±
                    tooth = convert_word_to_number(match.group(1))
                    if 1 <= tooth <= 32:
                        return {
                            'type': 'missing_teeth',
                            'values': [tooth],
                            'complete': True
                        }
        
        except Exception as e:
            logger.error(f"‚ùå Error extracting command data: {e}")
        
        return None
    
    async def execute_early_command(self, client_id: str, prediction: StreamingCommand) -> Optional[Dict]:
        """–î–æ—Å—Ä–æ—á–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã"""
        
        if not prediction.extracted_data or not prediction.extracted_data.get('complete', False):
            logger.warning(f"‚ö†Ô∏è Cannot execute incomplete command: {prediction.pattern_type}")
            return None
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
            data = prediction.extracted_data
            
            result = {
                'success': True,
                'tooth_number': data.get('tooth_number'),
                'measurement_type': data['type'],
                'surface': data.get('surface'),
                'position': data.get('position'),
                'values': data.get('values', []),
                'confidence': prediction.confidence,
                'message': self.format_command_message(data),
                'timestamp': prediction.timestamp,
                'early_execution': True,
                'streaming_prediction': True,
                'system': 'streaming_predictor_v1'
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º measurements –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            result['measurements'] = self.format_measurements(data)
            
            logger.info(f"üöÄ EARLY EXECUTION: {result['message']}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Early execution error: {e}")
            return None
    
    def format_command_message(self, data: Dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã"""
        
        cmd_type = data['type']
        tooth = data.get('tooth_number')
        values = data.get('values', [])
        
        if cmd_type == 'probing_depth':
            surface = data.get('surface', 'buccal')
            return f"‚ö° STREAMING: Tooth {tooth} {surface} PD: {'-'.join(map(str, values))}mm"
        
        elif cmd_type == 'bleeding':
            surface = data.get('surface', 'buccal')
            position = data.get('position', 'distal')
            return f"‚ö° STREAMING: Tooth {tooth} {surface} {position} bleeding"
        
        elif cmd_type == 'mobility':
            grade = values[0] if values else 0
            return f"‚ö° STREAMING: Tooth {tooth} mobility grade {grade}"
        
        elif cmd_type == 'missing_teeth':
            teeth_list = ', '.join(map(str, values))
            return f"‚ö° STREAMING: Missing teeth {teeth_list}"
        
        return f"‚ö° STREAMING: {cmd_type} updated"
    
    def format_measurements(self, data: Dict) -> Dict:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ measurements –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞"""
        
        cmd_type = data['type']
        values = data.get('values', [])
        
        if cmd_type == 'probing_depth':
            return {'probing_depth': values}
        elif cmd_type == 'bleeding':
            return {'bleeding': values}
        elif cmd_type == 'mobility':
            return {'mobility': values[0] if values else 0}
        elif cmd_type == 'missing_teeth':
            return {'missing_teeth': values}
        
        return {}
    
    async def broadcast_early_execution(self, client_id: str, result: Dict, prediction_time_ms: float):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–æ—Å—Ä–æ—á–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        
        if not self.web_clients:
            return
        
        message = {
            "type": "periodontal_update",
            "client_id": client_id,
            "early_execution": True,
            "prediction_time_ms": prediction_time_ms,
            **result
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        message["streaming_indicator"] = True
        message["execution_speed"] = "ULTRA_FAST"
        
        await self.safe_broadcast(message)
        
        logger.info(f"üì§ EARLY EXECUTION broadcasted in {prediction_time_ms:.1f}ms")
    
    async def broadcast_prediction_feedback(self, client_id: str, prediction: StreamingCommand):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏"""
        
        if not self.web_clients:
            return
        
        message = {
            "type": "streaming_prediction",
            "client_id": client_id,
            "pattern_type": prediction.pattern_type,
            "confidence": prediction.confidence,
            "partial_text": prediction.partial_text,
            "state": prediction.state.value,
            "timestamp": prediction.timestamp
        }
        
        await self.safe_broadcast(message)
    
    async def safe_broadcast(self, message: Dict):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤—Å–µ–º –∫–ª–∏–µ–Ω—Ç–∞–º"""
        
        import json
        message_json = json.dumps(message)
        disconnected = set()
        
        for client in list(self.web_clients):
            try:
                await asyncio.wait_for(client.send(message_json), timeout=0.5)
            except Exception as e:
                logger.debug(f"Client broadcast error: {e}")
                disconnected.add(client)
        
        for client in disconnected:
            self.web_clients.discard(client)
    
    def cleanup_client_stream(self, client_id: str):
        """–û—á–∏—Å—Ç–∫–∞ –ø–æ—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞"""
        if client_id in self.active_streams:
            del self.active_streams[client_id]
            logger.debug(f"üßπ Cleaned up stream for {client_id}")
    
    def get_streaming_stats(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        return {
            **self.stats,
            'active_streams': len(self.active_streams),
            'average_words_per_prediction': self._calculate_avg_words(),
            'execution_rate': (self.stats['early_executions'] / max(1, self.stats['predictions_made'])) * 100
        }
    
    def _calculate_avg_words(self) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
        if not self.active_streams:
            return 0.0
        
        total_words = sum(stream['word_count'] for stream in self.active_streams.values())
        return total_words / len(self.active_streams)

# =============================================================================
# –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° –û–°–ù–û–í–ù–´–ú –ü–†–û–¶–ï–°–°–û–†–û–ú
# =============================================================================

def integrate_streaming_predictor(base_processor, web_clients_ref):
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞ —Å –æ—Å–Ω–æ–≤–Ω—ã–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º"""
    
    predictor = StreamingPredictor(web_clients_ref)
    base_processor.streaming_predictor = predictor
    
    # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞–Ω–∫–æ–≤
    original_process_chunk = base_processor.process_audio_chunk
    
    def enhanced_process_chunk_with_streaming(client_id, audio_chunk):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–æ–≤ —Å –ø–æ—Ç–æ–∫–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
        
        # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        result = original_process_chunk(client_id, audio_chunk)
        
        # –ü–æ—Ç–æ–∫–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ —á–∞—Å—Ç–∏—á–Ω—ã—Ö –±—É—Ñ–µ—Ä–∞—Ö
        if hasattr(base_processor, 'segmentation_processor'):
            seg_processor = base_processor.segmentation_processor
            
            if hasattr(seg_processor, 'client_buffers'):
                buffer = seg_processor.client_buffers.get(client_id)
                
                if buffer and hasattr(buffer, 'audio_buffer') and len(buffer.audio_buffer) > 16000:  # 1+ —Å–µ–∫—É–Ω–¥–∞
                    
                    # –ë—ã—Å—Ç—Ä–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    try:
                        preview_audio = buffer.audio_buffer[-24000:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 1.5 —Å–µ–∫—É–Ω–¥—ã
                        
                        if hasattr(base_processor, 'asr') and hasattr(base_processor.asr, 'transcribe_fast_preview'):
                            quick_text, _, _ = base_processor.asr.transcribe_fast_preview(preview_audio)
                            
                            if quick_text and len(quick_text.split()) >= 6:
                                # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
                                asyncio.create_task(
                                    predictor.process_streaming_chunk(client_id, quick_text, preview_audio)
                                )
                                
                    except Exception as e:
                        logger.debug(f"Streaming analysis error: {e}")
        
        return result
    
    base_processor.process_audio_chunk = enhanced_process_chunk_with_streaming
    
    logger.info("üîÆ STREAMING PREDICTOR integrated for ULTRA-FAST response")
    return base_processor

# =============================================================================
# –£–õ–¨–¢–†–ê-–ë–´–°–¢–†–´–ï ASR –ù–ê–°–¢–†–û–ô–ö–ò
# =============================================================================

class UltraFastASR:
    """–£–ª—å—Ç—Ä–∞-–±—ã—Å—Ç—Ä—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è ASR"""
    
    @staticmethod
    def get_speed_optimized_params():
        """–ü–∞—Ä–∞–º–µ—Ç—Ä—ã ASR –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏"""
        return {
            'beam_size': 1,              # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π beam
            'best_of': 1,               # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥
            'temperature': 0.0,         # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥
            'no_speech_threshold': 0.9, # –í—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞ —Ç–∏—à–∏–Ω—ã
            'compression_ratio_threshold': 1.5,  # –ù–∏–∑–∫–∏–π –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            'condition_on_previous_text': False,  # –ë–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            'without_timestamps': True,  # –ë–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
            'word_timestamps': False,   # –ë–µ–∑ —Å–ª–æ–≤-–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
            'vad_filter': True,         # –§–∏–ª—å—Ç—Ä VAD
            'suppress_blank': True,     # –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö
            'suppress_tokens': [-1],    # –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
        }
    
    @staticmethod
    def setup_ultra_fast_model(asr_instance):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —É–ª—å—Ç—Ä–∞-–±—ã—Å—Ç—Ä–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        asr_instance.speed_params = UltraFastASR.get_speed_optimized_params()
        
        # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –º–µ—Ç–æ–¥ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        original_transcribe = asr_instance.transcribe
        
        def ultra_fast_transcribe(audio_np):
            """–£–ª—å—Ç—Ä–∞-–±—ã—Å—Ç—Ä–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è"""
            
            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —ç–Ω–µ—Ä–≥–∏–∏
            rms_energy = np.sqrt(np.mean(audio_np ** 2))
            if rms_energy < 0.001:  # –°–ª–∏—à–∫–æ–º —Ç–∏—Ö–æ
                return "NO_SPEECH_DETECTED", 0.0, 0.001
            
            # –£–∫–æ—Ä–æ—á–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            if len(audio_np) > 80000:  # –ë–æ–ª—å—à–µ 5 —Å–µ–∫—É–Ω–¥
                audio_np = audio_np[:80000]  # –û–±—Ä–µ–∑–∞–µ–º
            
            start_time = time.time()
            
            try:
                segments, info = asr_instance.model.transcribe(
                    audio_np,
                    language="en",
                    **asr_instance.speed_params
                )
                
                text_segments = [segment.text.strip() for segment in segments if segment.text]
                full_text = " ".join(text_segments).strip()
                
                confidence = getattr(info, 'language_probability', 0.8)
                processing_time = time.time() - start_time
                
                return full_text or "NO_SPEECH_DETECTED", confidence, processing_time
                
            except Exception as e:
                logger.error(f"Ultra-fast transcribe error: {e}")
                return f"ERROR: {str(e)[:50]}", 0.0, time.time() - start_time
        
        asr_instance.transcribe = ultra_fast_transcribe
        logger.info("‚ö° ULTRA-FAST ASR mode enabled")

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
    
    async def test_streaming_predictor():
        """–¢–µ—Å—Ç –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞"""
        
        print("üîÆ Testing STREAMING PREDICTOR")
        print("=" * 50)
        
        predictor = StreamingPredictor(set())
        
        test_texts = [
            "probing depth on tooth",
            "probing depth on tooth number fourteen",
            "probing depth on tooth number fourteen buccal",
            "probing depth on tooth number fourteen buccal surface three",
            "probing depth on tooth number fourteen buccal surface three two four"
        ]
        
        for i, text in enumerate(test_texts):
            print(f"\nStep {i+1}: '{text}'")
            
            result = await predictor.process_streaming_chunk("test", text, np.array([]))
            
            if result:
                print(f"  ‚ö° EARLY EXECUTION: {result['message']}")
            else:
                print(f"  ‚è≥ Waiting for more data...")
        
        stats = predictor.get_streaming_stats()
        print(f"\nüìä Stats: {stats}")
    
    asyncio.run(test_streaming_predictor())